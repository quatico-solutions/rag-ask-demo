# =============================================================================
# AI Provider Configuration
# =============================================================================

# Choose which provider to use for completions (chat): 'openai' or 'lmstudio'
AI_COMPLETION_PROVIDER=openai
# AI_COMPLETION_PROVIDER=lmstudio

# Choose which provider to use for embeddings: 'openai' or 'lmstudio'  
AI_EMBEDDING_PROVIDER=openai
# AI_EMBEDDING_PROVIDER=lmstudio

# =============================================================================
# OpenAI Configuration
# =============================================================================

# Required when using OpenAI provider
# Get your API key from https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-openai-api-key-here

# OpenAI models for completions (when AI_COMPLETION_PROVIDER=openai)
AI_COMPLETION_MODEL=gpt-3.5-turbo
# AI_COMPLETION_MODEL=gpt-4
# AI_COMPLETION_MODEL=gpt-4-turbo

# OpenAI models for embeddings (when AI_EMBEDDING_PROVIDER=openai)
AI_EMBEDDING_MODEL=text-embedding-ada-002
# AI_EMBEDDING_MODEL=text-embedding-3-small
# AI_EMBEDDING_MODEL=text-embedding-3-large

# =============================================================================
# LMStudio Configuration
# =============================================================================

# Required when using LMStudio provider
# Default LMStudio server URL (adjust port if needed)
# LMSTUDIO_BASE_URL=http://localhost:1234/v1

# LMStudio models for completions (when AI_COMPLETION_PROVIDER=lmstudio)
# Use the exact model name as it appears in LMStudio
# Recommended: 7B-13B parameter models for good performance/quality balance
# AI_COMPLETION_MODEL=llama-2-7b-chat
# AI_COMPLETION_MODEL=llama-2-13b-chat
# AI_COMPLETION_MODEL=mistral-7b-instruct
# AI_COMPLETION_MODEL=codellama-7b-instruct
# AI_COMPLETION_MODEL=zephyr-7b-beta

# LMStudio models for embeddings (when AI_EMBEDDING_PROVIDER=lmstudio)
# Recommended: Sentence transformer models for embeddings
# AI_EMBEDDING_MODEL=all-MiniLM-L6-v2
# AI_EMBEDDING_MODEL=all-mpnet-base-v2
# AI_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
# AI_EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2

# =============================================================================
# Mixed Provider Example Configuration
# =============================================================================

# Example: Use OpenAI for embeddings (better quality) and LMStudio for completions (cost savings)
# AI_COMPLETION_PROVIDER=lmstudio
# AI_COMPLETION_MODEL=llama-2-7b-chat
# AI_EMBEDDING_PROVIDER=openai
# AI_EMBEDDING_MODEL=text-embedding-ada-002
# OPENAI_API_KEY=sk-your-openai-api-key-here
# LMSTUDIO_BASE_URL=http://localhost:1234/v1

# =============================================================================
# Performance Notes
# =============================================================================

# For datasets with 100+ documents (e.g., pull request descriptions):
#
# OpenAI Recommendations:
# - Completions: gpt-3.5-turbo (fast, cost-effective) or gpt-4 (higher quality)
# - Embeddings: text-embedding-ada-002 (proven, reliable) or text-embedding-3-small (newer, faster)
#
# LMStudio Recommendations:
# - Completions: 7B-13B parameter models (llama-2-7b-chat, mistral-7b-instruct)
# - Embeddings: all-MiniLM-L6-v2 (fast) or all-mpnet-base-v2 (higher quality)
# - Ensure sufficient VRAM (8-16GB for 7B models, 16-24GB for 13B models)
# - Use GPU acceleration for best performance

# =============================================================================
# Development/Testing
# =============================================================================

# Mock OpenAI for tests (automatically set by test runners)
# USE_MOCK_OPENAI=true